{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import Image\n",
    "PATH = \"C:\\\\Users\\\\pitsi\\\\Desktop\\\\2024 Youtube\\\\4. Facebook LLama from groq\\\\\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bitwise-The-Year-Ahead-10-Crypto-Predictions-for-2024.pdf'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "pdf_path = 'Bitwise-The-Year-Ahead-10-Crypto-Predictions-for-2024.pdf'\n",
    "pdf_path[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models are a crucial advancement in the field of natural language processing (NLP) and artificial intelligence (AI). These models prioritize efficiency and speed, enabling them to process large amounts of text data quickly and make predictions or decisions rapidly.\n",
      "\n",
      "**Importance of Fast Language Models:**\n",
      "\n",
      "1. **Real-time Applications:** Fast language models can handle real-time tasks, such as chatbots, virtual assistants, and language translation systems. They can process user input and respond promptly, enhancing user experience.\n",
      "2. **Scalability:** Fast language models can handle large volumes of data and scale to meet the demands of complex applications, such as social media analysis, text summarization, and sentiment analysis.\n",
      "3. **Memory Efficiency:** Fast language models often use sparse memory representations, which reduce memory usage and make them more suitable for low-memory devices or deployments.\n",
      "4. **Improved Training Time:** Fast language models can train faster, reducing the time and resources required for model development and deployment.\n",
      "5. **Increased Productivity:** By automating tasks and providing rapid insights, fast language models can increase productivity in fields like data annotation, content generation, and language translation.\n",
      "6. **Enhanced Decision-Making:** Fast language models can analyze vast amounts of language data, providing critical insights and recommendations on marketing campaigns, business strategy, and more.\n",
      "7. **Edge AI and IoT:** Fast language models can be executed on edge devices (e.g., smartphones, smart speakers) or employed in IoT scenarios (e.g., voice assistants in smart homes), enabling real-time processing and immediate responses.\n",
      "8. **Dialogue Systems:** Fast language models are essential for building conversational dialogue systems, such as chatbots and voice assistants, which require rapid context switching and response generation.\n",
      "\n",
      "**Techniques For Fast Language Models:**\n",
      "\n",
      "1. **Model pruning:** removing unnecessary parameters to reduce model size and increase speed.\n",
      "2. **Knowledge distillation:** transferring knowledge from a larger model to a smaller one, preserving relevant information.\n",
      "3. **Dynamic routing:** adaptive routing that optimizes model execution based on input data.\n",
      "4. **Mixed-precision training:** using lower precision floating-point operations to speed up training.\n",
      "5. **Efficient computation:** leveraging approximations, parallel processing, or in-parallel computing.\n",
      "\n",
      "**Examples of Fast Language Models:**\n",
      "\n",
      "1. **BERT FastPass:** a compressed version of the popular BERT model, optimized for speed and memory efficiency.\n",
      "2. **DistilBERT:** a distilled, more compact variant of BERT, preserving key characteristics while reducing complexity.\n",
      "3. **FunnelBERT:** a high-performance version of BERT, based on in-parallel computation and dynamic routing.\n",
      "\n",
      "Fast language models are transforming industries by facilitating real-time applications, scalability, and efficiency. As these models continue to evolve, they are poised to tackle increasingly complex NLP tasks and improve decision-making, productivity, and user experience.\n"
     ]
    }
   ],
   "source": [
    "# Testing if the API Works\n",
    "import os\n",
    "\n",
    "from groq import Groq\n",
    "\n",
    "# Initialize the Groq client\n",
    "client = Groq(api_key='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')\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"you are a helpful assistant.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)\n",
    "\n",
    "## Available models: https://console.groq.com/docs/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "I'll do my best to provide a summary of the given PDF document. However, please note that I won't be able to directly access the document but will make educated assumptions based on the title and general knowledge. If you could provide more context or information about the document, I'll be happy to provide a more accurate summary.\n",
      "\n",
      "From the title \"Bitwise - The Year Ahead - 10 Crypto Predictions for 2024.pdf,\" I assume the document is a report from Bitwise, a well-known cryptocurrency research firm. The report likely predicts trends, opportunities, and challenges in the cryptocurrency market for 2024.\n",
      "\n",
      "Based on general knowledge and common predictions in the cryptocurrency space, here's a possible summary:\n",
      "\n",
      "1. **Regulatory clarity**: The report might predict increasing regulatory clarity in the US and globally, with more clear guidance on regulations and compliance for cryptocurrency businesses.\n",
      "2. **Institutional investment growth**: Bitwise might forecast continued growth in institutional investment in the cryptocurrency market, driven by increasing adoption and acceptance of digital assets by traditional financial institutions.\n",
      "3. **DeFi's resurgence**: The report could predict a resurgence of Decentralized Finance (DeFi) projects, driven by improved security, usability, and scalability.\n",
      "4. **Stablecoins' expansion**: Bitwise might forecast continued growth in the adoption of stablecoins, which are cryptocurrencies pegged to the value of fiat currencies, as a store of value and a medium of exchange.\n",
      "5. **Cryptocurrency adoption in emerging markets**: The report could predict increasing adoption of cryptocurrencies in emerging markets, driven by the need for faster and cheaper cross-border payments.\n",
      "6. **Security concerns and best practices**: Bitwise might emphasize the importance of security in the cryptocurrency space, with recommendations for best practices and mitigation strategies for common threats.\n",
      "7. **Scalable blockchain solutions**: The report could highlight the need for scalable blockchain solutions to support the growing demand for cryptocurrency transactions.\n",
      "8. **Quantum Computing and cryptography**: Bitwise might discuss the potential impact of quantum computing on cryptography and the need for post-quantum cryptographic algorithms.\n",
      "9. **Digital asset custody innovations**: The report could predict the development of innovative digital asset custody solutions to address the growing need for secure, user-friendly, and scalable storage of cryptocurrencies.\n",
      "10. **Environmental, Social, and Governance (ESG) considerations**: Bitwise might emphasize the importance of ESG factors in the cryptocurrency space, with a focus on sustainability, social responsibility, and good governance.\n",
      "\n",
      "Please note that this summary is speculative and based on general knowledge. If you have access to the actual document, I'd be happy to help you provide a more accurate summary.\n"
     ]
    }
   ],
   "source": [
    "def summarize_text(text):\n",
    "    try:\n",
    "        summary_response = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a helpful assistant.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Summarize the following text: {text}\"\n",
    "                }\n",
    "            ],\n",
    "            model=\"llama-3.1-8b-instant\",\n",
    "        )\n",
    "        return summary_response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "\n",
    "summary = summarize_text(pdf_path)\n",
    "print(\"Summary:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "Based on the provided context, the main topic of the document \"Bitwise-The-Year-Ahead-10-Crypto-Predictions-for-2024.pdf\" appears to be the predictions and insights related to the cryptocurrency market for the year 2024.\n"
     ]
    }
   ],
   "source": [
    "def ask_question(context, question):\n",
    "    try:\n",
    "        answer_response = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a helpful assistant.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Context: {context} Question: {question}\"\n",
    "                }\n",
    "            ],\n",
    "            model=\"llama-3.1-8b-instant\",\n",
    "        )\n",
    "        return answer_response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "\n",
    "question = \"What is the main topic of the document?\"\n",
    "answer = ask_question(pdf_path, question)\n",
    "print(\"Answer:\")\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
